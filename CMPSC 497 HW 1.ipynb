{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the GloVe Embeddings\n",
    "- Purpose: <br>\n",
    "  This function reads a GloVe file (a plain-text file) where each line contains a word followed by its vector (300 numbers in our case).\n",
    "- How It Works: <br>\n",
    "    - The file is opened, and for each line, the first element (the word) is separated from its numeric vector.\n",
    "    - The vector components are converted into a NumPy array (for efficient numerical operations).\n",
    "    - A dictionary (embeddings_index) is built where each word is a key, and its associated vector is the value.\n",
    "- Outcome: <br>\n",
    "  After running this cell, I have a dictionary (glove_embeddings) with pre-trained 300-dimensional word vectors.\n",
    "\n",
    "[Link to download GloVe](https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors from GloVe.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split() # Split the line into individual elements\n",
    "            word = values[0] # The first element is the word itself\n",
    "            coefs = np.asarray(values[1:], dtype='float32') # The remaining values are the vector components\n",
    "            embeddings_index[word] = coefs # Store the vector in a dictionary keyed by the word\n",
    "    return embeddings_index\n",
    "\n",
    "# Specify the path to the GloVe file (e.g., 'glove.6B.300d.txt')\n",
    "glove_file = \"C:/Users/CommAdmin/Downloads/glove.6B/glove.6B.300d.txt\"  \n",
    "glove_embeddings = load_glove_embeddings(glove_file)\n",
    "print(f\"Loaded {len(glove_embeddings)} word vectors from GloVe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the POS Tagging Dataset\n",
    "Load the POS tagging dataset from Hugging Face.\n",
    "- The load_dataset function downloads and prepares the dataset.\n",
    "- The dataset has a split called \"train\"; each example is a dictionary with keys like \"words\" (a list of tokens) and \"labels\" (the corresponding POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['Confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'September', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'July', 'and', 'August', \"'s\", 'near-record', 'deficits', '.'], 'labels': ['NN', 'IN', 'DT', 'NN', 'VBZ', 'RB', 'VBN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NNP', ',', 'JJ', 'IN', 'NN', 'NN', ',', 'VB', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'CC', 'NNP', 'POS', 'JJ', 'NNS', '.']}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (we use the \"train\" split for both training and test as described)\n",
    "dataset = load_dataset(\"batterydata/pos_tagging\")\n",
    "data = dataset[\"train\"]\n",
    "\n",
    "# Inspect the first example\n",
    "print(data[0])\n",
    "print(type(data[0]))  # Should print <class 'dict'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting All Tokens and Building an Embedding Cache Using GloVe\n",
    "- Purpose: <br>\n",
    "  Create a “cache” of embeddings for every unique token in the dataset.\n",
    "- How It Works:\n",
    "    - get_all_tokens function: <br>\n",
    "      Iterates through every example (sentence) in the dataset and collects all words.\n",
    "    - unique_tokens = set(all_tokens): <br>\n",
    "      Converts the list of tokens into a set to remove duplicates (so each word is processed only once).\n",
    "    - Building the Cache: <br>\n",
    "      For each unique token, the code:\n",
    "        - Checks if the token exists in the GloVe embeddings (case-sensitive).\n",
    "        - If not, it checks the lowercase version (since GloVe is usually in lowercase).\n",
    "        - If still not found, it assigns a zero vector (an array of zeros).\n",
    "- Outcome: <br>\n",
    "  You have an embedding_cache dictionary that quickly gives you the vector for any token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 24847\n"
     ]
    }
   ],
   "source": [
    "# Iterates through every example (sentence) in the dataset and collects all words.\n",
    "def get_all_tokens(examples):\n",
    "    tokens = []\n",
    "    for example in examples:\n",
    "        tokens.extend(example['words'])\n",
    "    return tokens\n",
    "\n",
    "# Get all tokens from the entire dataset (for building the cache)\n",
    "all_tokens = get_all_tokens(data)\n",
    "unique_tokens = set(all_tokens) # Converts the list of tokens into a set to remove duplicates (so each word is processed only once).\n",
    "print(f\"Number of unique tokens: {len(unique_tokens)}\")\n",
    "\n",
    "embedding_cache = {}\n",
    "embedding_dim = 300  # Using the 300d GloVe embeddings\n",
    "\n",
    "for token in unique_tokens:\n",
    "    if token in glove_embeddings:\n",
    "        embedding_cache[token] = glove_embeddings[token]\n",
    "    elif token.lower() in glove_embeddings:\n",
    "        embedding_cache[token] = glove_embeddings[token.lower()]\n",
    "    else:\n",
    "        # If the token is not found in GloVe, assign a zero vector.\n",
    "        embedding_cache[token] = np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Function to Create Context-Augmented Features\n",
    "- Purpose: <br>\n",
    "  Enhance each token’s feature vector with information about its neighboring words.\n",
    "- How It Works:\n",
    "    - Padding: <br>\n",
    "      Creates zero vectors to pad the beginning and end of the sentence so that every token (including those at the boundaries) can have the same-sized context window.\n",
    "    - Context Extraction: <br>\n",
    "      For each token in the sentence, the function extracts the embeddings for the token itself and its neighbors (one token before and one after, if available).\n",
    "    - Flattening: <br>\n",
    "      The neighboring embeddings are concatenated (flattened) into a single vector.\n",
    "- Outcome: <br>\n",
    "  Each token is now represented by a feature vector that is longer (e.g., 900 dimensions when using a window of 1 and 300-dimensional embeddings) and contains context information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_features(sentence_embeddings, window_size=1):\n",
    "    \"\"\"\n",
    "    Given an array of token embeddings for a sentence (shape: (n_tokens, embed_dim)),\n",
    "    return an array of context features for each token by concatenating the embeddings\n",
    "    from a window of size `window_size` on both sides.\n",
    "    \n",
    "    At sentence boundaries, pad with zeros.\n",
    "    \"\"\"\n",
    "    n_tokens, embed_dim = sentence_embeddings.shape\n",
    "    # Create a padding array (zeros) for the beginning and end\n",
    "    pad = np.zeros((window_size, embed_dim))\n",
    "    padded = np.vstack([pad, sentence_embeddings, pad])\n",
    "    \n",
    "    features = []\n",
    "    for i in range(window_size, window_size + n_tokens):\n",
    "        # Extract embeddings for the context window (previous, current, next)\n",
    "        context = padded[i - window_size: i + window_size + 1].flatten()\n",
    "        features.append(context)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Feature Matrices and Label Vectors\n",
    "- Purpose:<br>\n",
    "  Transform the dataset from a list of sentences (with each sentence as a list of tokens) into a flat feature matrix for training and testing.\n",
    "- How It Works:<br>\n",
    "    - For Training:<br>\n",
    "      The code iterates over the first 1000 sentences. For each sentence:\n",
    "        - It retrieves the word embeddings (using the cache).\n",
    "        - It calls create_context_features to build a feature vector for each token.\n",
    "        - It collects these feature vectors and the corresponding labels (POS tags) into lists.\n",
    "    - For Testing:<br>\n",
    "      The same procedure is applied over all sentences in the dataset.\n",
    "    - Flattening:<br>\n",
    "      Since each sentence produces an array of feature vectors, the code uses np.vstack to stack them into one large NumPy array.\n",
    "- Outcome:<br>\n",
    "X_train_context and X_test_context become matrices where each row corresponds to a token’s feature vector.<br>\n",
    "y_train_context and y_test_context are arrays of labels for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features: (23969, 900)\n",
      "Shape of testing features: (321815, 900)\n"
     ]
    }
   ],
   "source": [
    "# Select the first 1000 sentences for training\n",
    "train_sentences = data.select(range(1000))\n",
    "# Use all sentences for testing\n",
    "test_sentences = data\n",
    "\n",
    "# Initialize lists to hold features and corresponding labels\n",
    "X_train_context = []\n",
    "y_train_context = []\n",
    "X_test_context = []\n",
    "y_test_context = []\n",
    "\n",
    "# Process training sentences\n",
    "for example in train_sentences:\n",
    "    words = example['words']\n",
    "    labels = example['labels']\n",
    "    # Build an array of embeddings for the sentence using the embedding cache\n",
    "    sent_embeddings = np.array([embedding_cache[word] for word in words])\n",
    "    # Create context-augmented features (for window_size=1, feature vector length = 3 * 300 = 900)\n",
    "    sent_features = create_context_features(sent_embeddings, window_size=1)\n",
    "    X_train_context.append(sent_features)\n",
    "    y_train_context.extend(labels)\n",
    "\n",
    "# Process test sentences\n",
    "for example in test_sentences:\n",
    "    words = example['words']\n",
    "    labels = example['labels']\n",
    "    sent_embeddings = np.array([embedding_cache[word] for word in words])\n",
    "    sent_features = create_context_features(sent_embeddings, window_size=1)\n",
    "    X_test_context.append(sent_features)\n",
    "    y_test_context.extend(labels)\n",
    "\n",
    "# Flatten the list of arrays (each sentence's features) into a single array\n",
    "X_train_context = np.vstack(X_train_context)\n",
    "X_test_context = np.vstack(X_test_context)\n",
    "y_train_context = np.array(y_train_context)\n",
    "y_test_context = np.array(y_test_context)\n",
    "\n",
    "print(\"Shape of training features:\", X_train_context.shape)\n",
    "print(\"Shape of testing features:\", X_test_context.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the POS Tag Labels\n",
    "- Purpose:<br>\n",
    "  Convert the POS tags into numeric labels that the classifier can work with.\n",
    "- How It Works:\n",
    "    - LabelEncoder:<br>\n",
    "      A tool from scikit-learn that assigns each unique label a unique integer.\n",
    "    - Fitting:<br>\n",
    "      We fit the encoder on the union of training and test labels (so that all possible labels are recognized).\n",
    "    - Transforming:<br>\n",
    "      The textual labels are converted into integer arrays.\n",
    "- Outcome:<br>\n",
    "  You now have y_train_enc and y_test_enc as numeric representations of your POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique POS tags: ['#' '$' \"''\" '(' ')' ',' '-LRB-' '-NONE-' '-RRB-' '.' ':' 'CC' 'CD' 'DT'\n",
      " 'EX' 'FW' 'IN' 'JJ' 'JJR' 'JJS' 'LS' 'MD' 'NN' 'NNP' 'NNPS' 'NNS' 'PDT'\n",
      " 'POS' 'PRP' 'PRP$' 'RB' 'RBR' 'RBS' 'RP' 'SYM' 'TO' 'UH' 'VB' 'VBD' 'VBG'\n",
      " 'VBN' 'VBP' 'VBZ' 'WDT' 'WP' 'WP$' 'WRB' '``']\n"
     ]
    }
   ],
   "source": [
    "# Option: Fit the encoder on both training and test tags to cover all labels.\n",
    "all_tags = list(y_train_context) + list(y_test_context)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(all_tags)\n",
    "\n",
    "y_train_enc = encoder.transform(y_train_context)\n",
    "y_test_enc = encoder.transform(y_test_context)\n",
    "\n",
    "print(\"Unique POS tags:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Classifier (Logistic Regression)\n",
    "- Purpose:<br>\n",
    "  Train a Logistic Regression model to learn the mapping from token features (with context) to POS tag labels.\n",
    "- How It Works:\n",
    "    - Model Initialization:<br>\n",
    "      The classifier is set up with a maximum of 1000 iterations (to ensure convergence).\n",
    "    - Training:<br>\n",
    "      The classifier’s .fit() method is called with the training features and labels.\n",
    "- Outcome:<br>\n",
    "  The classifier learns patterns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_context, y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8419\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       1.00      0.85      0.92        48\n",
      "           $       1.00      0.99      0.99      2529\n",
      "          ''       1.00      0.99      1.00      2295\n",
      "           (       0.43      0.22      0.29       351\n",
      "           )       0.23      0.16      0.19       358\n",
      "           ,       1.00      1.00      1.00     16256\n",
      "       -LRB-       0.00      0.00      0.00        67\n",
      "      -NONE-       0.00      0.00      0.00      4106\n",
      "       -RRB-       0.00      0.00      0.00        70\n",
      "           .       1.00      0.99      1.00     13210\n",
      "           :       1.00      0.92      0.96      1690\n",
      "          CC       0.98      0.98      0.98      8022\n",
      "          CD       0.86      0.89      0.88     12055\n",
      "          DT       0.98      0.97      0.98     27541\n",
      "          EX       0.92      0.97      0.94       313\n",
      "          FW       0.82      0.20      0.32        45\n",
      "          IN       0.93      0.96      0.95     33979\n",
      "          JJ       0.63      0.68      0.65     19706\n",
      "         JJR       0.82      0.77      0.79      1250\n",
      "         JJS       0.86      0.67      0.75       562\n",
      "          LS       0.00      0.00      0.00        10\n",
      "          MD       0.98      0.95      0.96      3183\n",
      "          NN       0.77      0.78      0.77     44657\n",
      "         NNP       0.74      0.77      0.76     30882\n",
      "        NNPS       0.63      0.15      0.24       680\n",
      "         NNS       0.74      0.79      0.76     20344\n",
      "         PDT       1.00      0.04      0.08        76\n",
      "         POS       0.98      0.98      0.98      2679\n",
      "         PRP       0.98      0.94      0.96      5829\n",
      "        PRP$       0.98      0.99      0.99      2811\n",
      "          RB       0.67      0.76      0.71      9807\n",
      "         RBR       0.82      0.48      0.61       489\n",
      "         RBS       0.85      0.73      0.78       262\n",
      "          RP       0.73      0.04      0.08       254\n",
      "         SYM       0.00      0.00      0.00         7\n",
      "          TO       1.00      1.00      1.00      7591\n",
      "          UH       0.00      0.00      0.00        19\n",
      "          VB       0.84      0.85      0.85      8848\n",
      "         VBD       0.80      0.80      0.80     10302\n",
      "         VBG       0.67      0.65      0.66      4928\n",
      "         VBN       0.67      0.64      0.65      7178\n",
      "         VBP       0.81      0.71      0.76      4273\n",
      "         VBZ       0.92      0.88      0.90      6941\n",
      "         WDT       0.87      0.76      0.81      1416\n",
      "          WP       1.00      0.95      0.97       814\n",
      "         WP$       1.00      0.04      0.08        47\n",
      "         WRB       0.97      0.76      0.85       682\n",
      "          ``       1.00      1.00      1.00      2353\n",
      "\n",
      "    accuracy                           0.84    321815\n",
      "   macro avg       0.75      0.64      0.66    321815\n",
      "weighted avg       0.83      0.84      0.84    321815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CommAdmin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\CommAdmin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\CommAdmin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_context)\n",
    "\n",
    "accuracy = accuracy_score(y_test_enc, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_enc, y_pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
